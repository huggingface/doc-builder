&amp;lt;script>
import Tip from "../../Tip.svelte";
import Youtube from "../../Youtube.svelte";	
export let fw: "pt" | "tf"
&amp;lt;/script>

<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Utilities for pipelines

This page lists all the utility functions the library provides for pipelines.

Most of those are only useful if you are studying the code of the models in the library.


## Argument handling

<a id='transformers.pipelines.ArgumentHandler'></a>
> **class transformers.pipelines.ArgumentHandler**()


Base interface for handling arguments for each [Pipeline](main_classes/pipelines.html#transformers.Pipeline).


<a id='transformers.pipelines.ZeroShotClassificationArgumentHandler'></a>
> **class transformers.pipelines.ZeroShotClassificationArgumentHandler**()


Handles arguments for zero-shot for text classification by turning each possible label into an NLI
premise/hypothesis pair.


<a id='transformers.pipelines.QuestionAnsweringArgumentHandler'></a>
> **class transformers.pipelines.QuestionAnsweringArgumentHandler**()


QuestionAnsweringPipeline requires the user to provide multiple arguments (i.e. question & context) to be mapped to
internal `SquadExample`.

QuestionAnsweringArgumentHandler manages all the possible to create a `SquadExample` from the
command-line supplied arguments.


## Data format

<a id='transformers.PipelineDataFormat'></a>
> **class transformers.PipelineDataFormat**(output_path: typing.Optional[str], input_path: typing.Optional[str], column: typing.Optional[str], overwrite: bool = False)


Base class for all the pipeline supported data format both for reading and writing. Supported data formats
currently includes:

- JSON
- CSV
- stdin/stdout (pipe)

`PipelineDataFormat` also includes some utilities to work with multi-columns like mapping from datasets
columns to pipelines keyword arguments through the `dataset_kwarg_1=dataset_column_1` format.

> Parameters

- **output_path** (`str`, _optional_) -- Where to save the outgoing data.
- **input_path** (`str`, _optional_) -- Where to look for the input data.
- **column** (`str`, _optional_) -- The column to read.
- **overwrite** (`bool`, _optional_, defaults to `False`) --
  Whether or not to overwrite the `output_path`.


<a id='transformers.PipelineDataFormat.from_str'></a>
> **from\_str**(format: str, output_path: typing.Optional[str], input_path: typing.Optional[str], column: typing.Optional[str], overwrite = False)


Creates an instance of the right subclass of [PipelineDataFormat](internal/pipelines_utils.html#transformers.PipelineDataFormat) depending on
`format`.

> Parameters

format -- (`str`):
The format of the desired pipeline. Acceptable values are `"json"`, `"csv"` or `"pipe"`.
- **output_path** (`str`, _optional_) --
  Where to save the outgoing data.
- **input_path** (`str`, _optional_) --
  Where to look for the input data.
- **column** (`str`, _optional_) --
  The column to read.
- **overwrite** (`bool`, _optional_, defaults to `False`) --
  Whether or not to overwrite the `output_path`.

> Returns

The proper data format.

> Return type

[PipelineDataFormat](internal/pipelines_utils.html#transformers.PipelineDataFormat)


<a id='transformers.PipelineDataFormat.save'></a>
> **save**(self, data: typing.Union[dict, typing.List[dict]])


Save the provided data object with the representation for the current
[PipelineDataFormat](internal/pipelines_utils.html#transformers.PipelineDataFormat).

> Parameters

- **data** (`dict` or list of `dict`) -- The data to store.


<a id='transformers.PipelineDataFormat.save_binary'></a>
> **save\_binary**(self, data: typing.Union[dict, typing.List[dict]])


Save the provided data object as a pickle-formatted binary data on the disk.

> Parameters

- **data** (`dict` or list of `dict`) -- The data to store.

> Returns

Path where the data has been saved.

> Return type

`str`


<a id='transformers.CsvPipelineDataFormat'></a>
> **class transformers.CsvPipelineDataFormat**(output_path: typing.Optional[str], input_path: typing.Optional[str], column: typing.Optional[str], overwrite = False)


Support for pipelines using CSV data format.

> Parameters

- **output_path** (`str`, _optional_) -- Where to save the outgoing data.
- **input_path** (`str`, _optional_) -- Where to look for the input data.
- **column** (`str`, _optional_) -- The column to read.
- **overwrite** (`bool`, _optional_, defaults to `False`) --
  Whether or not to overwrite the `output_path`.


<a id='transformers.CsvPipelineDataFormat.save'></a>
> **save**(self, data: typing.List[dict])


Save the provided data object with the representation for the current
[PipelineDataFormat](internal/pipelines_utils.html#transformers.PipelineDataFormat).

> Parameters

- **data** (`List[dict]`) -- The data to store.


<a id='transformers.JsonPipelineDataFormat'></a>
> **class transformers.JsonPipelineDataFormat**(output_path: typing.Optional[str], input_path: typing.Optional[str], column: typing.Optional[str], overwrite = False)


Support for pipelines using JSON file format.

> Parameters

- **output_path** (`str`, _optional_) -- Where to save the outgoing data.
- **input_path** (`str`, _optional_) -- Where to look for the input data.
- **column** (`str`, _optional_) -- The column to read.
- **overwrite** (`bool`, _optional_, defaults to `False`) --
  Whether or not to overwrite the `output_path`.


<a id='transformers.JsonPipelineDataFormat.save'></a>
> **save**(self, data: dict)


Save the provided data object in a json file.

> Parameters

- **data** (`dict`) -- The data to store.


<a id='transformers.PipedPipelineDataFormat'></a>
> **class transformers.PipedPipelineDataFormat**(output_path: typing.Optional[str], input_path: typing.Optional[str], column: typing.Optional[str], overwrite: bool = False)


Read data from piped input to the python process. For multi columns data, columns should separated by 	

If columns are provided, then the output will be a dictionary with &lcubcolumn_x: value_x}

> Parameters

- **output_path** (`str`, _optional_) -- Where to save the outgoing data.
- **input_path** (`str`, _optional_) -- Where to look for the input data.
- **column** (`str`, _optional_) -- The column to read.
- **overwrite** (`bool`, _optional_, defaults to `False`) --
  Whether or not to overwrite the `output_path`.


<a id='transformers.PipedPipelineDataFormat.save'></a>
> **save**(self, data: dict)


Print the data.

> Parameters

- **data** (`dict`) -- The data to store.


## Utilities

<a id='transformers.pipelines.PipelineException'></a>
> **class transformers.pipelines.PipelineException**(task: str, model: str, reason: str)


Raised by a [Pipeline](main_classes/pipelines.html#transformers.Pipeline) when handling __call__.

> Parameters

- **task** (`str`) -- The task of the pipeline.
- **model** (`str`) -- The model used by the pipeline.
- **reason** (`str`) -- The error message to display.

